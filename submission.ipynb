{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas --quiet\n",
    "# !pip install openpyxl --quiet\n",
    "# !pip install sklearn --quiet\n",
    "# !pip install matplotlib --quiet\n",
    "# !pip install seaborn --quiet\n",
    "# !pip install xgboost --quiet\n",
    "# !pip install statsmodels -- quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import statsmodels.api as sm\n",
    "import statistics as st\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('health_dataset.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preliminary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Before dropping duplicates')\n",
    "print(f'Number of duplicates: {data.shape[0] - data.drop_duplicates().shape[0]}')\n",
    "data.drop_duplicates(inplace=True)\n",
    "print('')\n",
    "print('After dropping duplicates')\n",
    "print(f'Number of duplicates: {data.shape[0] - data.drop_duplicates().shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test,trainLab,testLab = train_test_split(data[[col for col in data.columns if col != 'target']],data['target'],test_size=0.2,random_state=314)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary sorting dataset into numerical and categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[[col for col in train.columns if 'scaled' not in col]]\n",
    "var_type = {'num':['age','trestbps','chol','thalach']}\n",
    "var_type['cat'] = [col for col in train.columns if col not in var_type['num']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare a Report About the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show the distribution of each variable\n",
    "\n",
    "cols = train.columns\n",
    "for i in range(0,len(cols),2):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(121)\n",
    "    plt.title(cols[i])\n",
    "    sns.histplot(train[cols[i]])\n",
    "    try:\n",
    "        plt.subplot(122)\n",
    "        plt.title(cols[i+1])\n",
    "        sns.histplot(train[cols[i+1]])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except:\n",
    "        pass\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measures of Centeral Tendency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def st_err(col):\n",
    "    return train[col].std()/np.sqrt(train[col].shape[0] - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in var_type['num']:\n",
    "    print(col)\n",
    "    print(train[col].mean())\n",
    "    print(st_err(col))\n",
    "    print('')\n",
    "\n",
    "for col in var_type['cat']:\n",
    "    print(col)\n",
    "    print(st.mode(train[col]))\n",
    "    print(st.mean(train[col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at correlations with target variable using heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummy = train.copy()\n",
    "train_dummy['label'] = trainLab\n",
    "train_dummy = train_dummy[[col for col in train_dummy.columns if 'scaled' not in col]]\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121)\n",
    "plt.title('Correlation Heatmap - All Variables')\n",
    "sns.heatmap(train_dummy.corr(),cmap='viridis')\n",
    "plt.subplot(122)\n",
    "plt.title('Correlation Heatmap - Top 5')\n",
    "sns.heatmap(train_dummy.corr().nlargest(5,'label'),cmap='viridis')\n",
    "\n",
    "# print(train_dummy.corr())\n",
    "train_dummy.corr().nlargest(6,'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(trainLab,train)\n",
    "olsres = model.fit()\n",
    "sum = olsres.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore using statsmodels.api.OLS() for feature selection based on p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline creation\n",
    "<ul style=\"list-style:none\">\n",
    "    <li>\n",
    "    1. Impute Missing Values // Scale/Encode Variables\n",
    "    </li>\n",
    "    <li>\n",
    "    2. Apply Num/Cat Pipeline to Numerical/Categorical Variables\n",
    "    </li>\n",
    "    <li>\n",
    "    3. Apply Classifier (Grid Search)\n",
    "    </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.\n",
    "num_pipeline = Pipeline([('si',SimpleImputer(strategy='median')),('std',StandardScaler())])\n",
    "cat_pipeline = Pipeline([('si',SimpleImputer(strategy='most_frequent')),('ohe',OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.\n",
    "preprocessing_pipeline = ColumnTransformer([('num',num_pipeline,var_type['num']),('cat',cat_pipeline,var_type['cat'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See params from logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.\n",
    "lr_base = LogisticRegression()\n",
    "l = len(train.columns)\n",
    "params_lr = {'tol':[1e-4,1e-3,1e-2,1e-1,1,10],'C':[1e-2,1e-1,1,10],'dual':[True,False]}\n",
    "cvlr = RandomizedSearchCV(lr_base,param_distributions=params_lr)\n",
    "pipeline_lr_base = Pipeline([('prep',preprocessing_pipeline),('lr_base',lr_base)])\n",
    "pipeline_lr_opt = Pipeline([('prep',preprocessing_pipeline),('cvlr',cvlr)])\n",
    "\n",
    "print('Logistic Regression Tuned')\n",
    "pipeline_lr_opt.fit(train,trainLab)\n",
    "print(classification_report(testLab,pipeline_lr_opt.predict(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See Params from RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.\n",
    "rf_base = RandomForestClassifier()\n",
    "params_rf = {'n_estimators':[100,500,1000,5000],'criterion':['gini','entropy'],'max_depth':[l//3,l//2,(2*l)//3]}\n",
    "cvrf = RandomizedSearchCV(rf_base,param_distributions=params_rf,n_iter=5)\n",
    "\n",
    "pipeline_rf_base = Pipeline([('prep',preprocessing_pipeline),('rf_base',rf_base)])\n",
    "pipeline_rf_opt = Pipeline([('prep',preprocessing_pipeline),('cvrf',cvrf)])\n",
    "\n",
    "print('Random Forest Tuned Model')\n",
    "pipeline_rf_opt.fit(train,trainLab)\n",
    "print(classification_report(testLab,pipeline_rf_opt.predict(test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mean_enc(col):\n",
    "#     mean_enc = {}\n",
    "#     df = train.copy()\n",
    "#     df['label'] = trainLab\n",
    "#     x = df.groupby(by=col).mean()['label']\n",
    "#     return {ind:x[ind] for ind in x.index}\n",
    "\n",
    "# for col in var_type['cat']:\n",
    "#     me = mean_enc(col)\n",
    "#     train[f'{col}_me'] = train[col].map(me)\n",
    "#     test[f'{col}_me'] = test[col].map(me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49528d0e90d7f7395c72c7f344322586e4dcc655c68720a36234acdbd4120d08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
